{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "keUpycTsbpEr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eDfFpD_be58",
    "outputId": "042273ed-13bc-4ec2-9251-53494b7ebe1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Using cached keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras_tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras_tuner) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras_tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Using cached kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from keras->keras_tuner) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from requests->keras_tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from requests->keras_tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from requests->keras_tuner) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from requests->keras_tuner) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from optree->keras->keras_tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from rich->keras->keras_tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from rich->keras->keras_tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\soura\\opencv_master\\opencv-env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
      "Using cached keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Using cached kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbNwaOy4bv6S",
    "outputId": "8701da61-9ae9-4f2f-c539-261b963281b3"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive')\n",
    "else:\n",
    "    path = r'C:/dev/machine_learning_project/deep_learning/classification/'\n",
    "    os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mytnuiWb1Iz"
   },
   "source": [
    "#Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "957wRJsQb5Au"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_excel('../../data/chiefs_knife_dataset.xlsx')\n",
    "index_Ra = dataframe.columns.get_loc('Ra') # index of the surface roughness column for inserting the class. label\n",
    "\n",
    "lower_specification_limit = 0.125 # lower bound of good quality product region\n",
    "upper_specification_limit = 0.215  # upper bound of good quality product region\n",
    "\n",
    "is_between_specification_bounds = (dataframe['Ra']>=lower_specification_limit) & (dataframe['Ra'] < upper_specification_limit)\n",
    "good_product_range = np.where(is_between_specification_bounds,\"good\",\"bad\")\n",
    "dataframe.insert(index_Ra, 'Quality',good_product_range) # encoding: good quality product := 1 and poor quality product := 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "ls-3dTs1gupF",
    "outputId": "6598c108-83a8-490f-e89c-bda76ed4d695"
   },
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlkbDJHCcYPm"
   },
   "source": [
    "# constructing Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDrXRplMcelq"
   },
   "outputs": [],
   "source": [
    "X = dataframe.loc[:,'Original_Linienanzahl':'DFT_Median_sobel_Bereich'].values\n",
    "y = dataframe['Quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RwEgExFl5sr",
    "outputId": "2286993f-9f9f-42b2-f647-6e95f670177e"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwBTIuN_l6gO",
    "outputId": "97d5ca74-b00e-49a5-f822-83ab6b4937da"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bep_JLkwlxKI"
   },
   "source": [
    "#Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Y3VzIZal4SH"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Thq7oj6nFjsr",
    "outputId": "930332e7-6da3-4b42-bf0f-7dd84b8b3dc4"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "fVno78yRj-lY",
    "outputId": "ac6f54af-80bc-4b9d-dcbd-a5799608a864"
   },
   "outputs": [],
   "source": [
    "dataframe['Quality'] = y\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RetU2TIdAPC"
   },
   "source": [
    "#Splitting dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPqpuDhpd8Hd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghYbDmL_dKV9"
   },
   "outputs": [],
   "source": [
    "test_size = 0.15\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmzvTBgQeid-"
   },
   "source": [
    "#Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cknpgDskePMn"
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ouv8AUijnf-t",
    "outputId": "82be70cd-06c4-4e8d-8cea-05c29f73d22e"
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EeLi6s8eu-Z"
   },
   "source": [
    "#Hyperparameter definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYu16O8IerIx"
   },
   "outputs": [],
   "source": [
    "# import keras_tuner as kt\n",
    "# from keras_tuner import HyperParameters\n",
    "\n",
    "# neurons_max = 1024\n",
    "# neurons_min = 32\n",
    "# neurons_step = 16\n",
    "# dropout_min = 0.0\n",
    "# dropout_max = 0.5\n",
    "# dropout_step = 0.1\n",
    "# l2_min = 0.0\n",
    "# l2_max = 0.1\n",
    "# l2_step = 0.01\n",
    "# learning_rates = [1e-2, 1e-3, 1e-4,1e-5]\n",
    "# activations = ['sigmoid', 'tanh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gwh1FU_e4kk"
   },
   "source": [
    "#Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB0P1hJYfcaa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LeakyReLU, ELU, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Nadam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "def set_activation(activation_name):\n",
    "    \"\"\"\n",
    "  set the activation function for the model\n",
    "  \"\"\"\n",
    "    if activation_name == 'leaky_relu':\n",
    "        activation = tf.keras.layers.LeakyReLU()\n",
    "    else:\n",
    "        activation = tf.keras.layers.Activation(activation_name)\n",
    "    return activation\n",
    "\n",
    "\n",
    "class DeepClassifierModel:\n",
    "    hp = kt.HyperParameters()\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "      initialize the hyperparameters for hyperparameter tuning\n",
    "      \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.neurons_max = 1024\n",
    "        self.neurons_min = 32\n",
    "        self.neurons_step = 16\n",
    "        self.learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "        self.activation_name = ['relu', 'tanh', 'selu', 'leaky_relu']\n",
    "        self.optimizer_name = ['adam', 'nadam', 'rmsprop', 'sgd']\n",
    "\n",
    "    def build_model(self, hp):\n",
    "        \"\"\"\n",
    "      create a NN architecture for the classifiction task\n",
    "      hp: hyperparameter for hyperparameter tuning\n",
    "      \"\"\"\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('hidden_1', min_value=self.neurons_min, max_value=self.neurons_max, step=self.neurons_step),\n",
    "            activation=set_activation(hp.Choice('activation_1', values=self.activation_name)),\n",
    "            input_dim=self.input_dim))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('hidden_2', min_value=self.neurons_min, max_value=self.neurons_max, step=self.neurons_step),\n",
    "            activation=set_activation(hp.Choice('activation_2', values=self.activation_name))))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('hidden_3', min_value=self.neurons_min, max_value=self.neurons_max, step=self.neurons_step),\n",
    "            activation=set_activation(hp.Choice('activation_3', values=self.activation_name))))\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('hidden_4', min_value=self.neurons_min, max_value=self.neurons_max, step=self.neurons_step),\n",
    "            activation=set_activation(hp.Choice('activation_4', values=self.activation_name))))\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('hidden_5', min_value=self.neurons_min, max_value=self.neurons_max, step=self.neurons_step),\n",
    "            activation=set_activation(hp.Choice('activation_5', values=self.activation_name))))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=self.set_optimizer(hp.Choice('optimizer', values=self.optimizer_name),hp.Choice('learning_rate', values=self.learning_rates)),\n",
    "                      loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        return model\n",
    "\n",
    "    def set_optimizer(self, optimizer_name,learn_rate):\n",
    "        \"\"\"\n",
    "      set the optimizer for the model\n",
    "      \"\"\"\n",
    "        if optimizer_name == 'adam':\n",
    "            return tf.keras.optimizers.Adam(learning_rate=learn_rate)\n",
    "        elif optimizer_name == 'sgd':\n",
    "            return tf.keras.optimizers.SGD(learning_rate=learn_rate)\n",
    "        elif optimizer_name == 'nadam':\n",
    "            return tf.keras.optimizers.Nadam(learning_rate=learn_rate)\n",
    "        elif optimizer_name == 'rmsprop':\n",
    "            return tf.keras.optimizers.RMSprop(learning_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1_sR_ADg3Hn"
   },
   "source": [
    "#random search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcFcGov1gyW4",
    "outputId": "7724387d-e9f6-4494-888a-cbcb6d43e9c0"
   },
   "outputs": [],
   "source": [
    "classifier = DeepClassifierModel(X_train.shape[1])\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "hypermodel=classifier.build_model,\n",
    "objective='val_accuracy',\n",
    "max_trials=60,\n",
    "executions_per_trial=1,\n",
    "overwrite=True,\n",
    "directory=\"hyperparameter_tuning_classifier\",\n",
    "project_name=\"simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHoNmErkhQDE",
    "outputId": "0e2b250f-7a47-4061-cc48-9ece34e729fd"
   },
   "outputs": [],
   "source": [
    "# callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(X_train, y_train, batch_size=16, epochs=15, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LTDmAxPNugms",
    "outputId": "020bdd2d-180f-4797-c87b-edd709a5e50e"
   },
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=8)\n",
    "models.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUkDZib4CJMM",
    "outputId": "613fc83e-ad0a-4d94-f840-296796dd047a"
   },
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1_drf3hCV4D"
   },
   "outputs": [],
   "source": [
    "# param = {'hidden_1': 288,\n",
    "#  'activation_1': 'relu',\n",
    "#  'hidden_2': 464,\n",
    "#  'activation_2': 'leaky_relu',\n",
    "#  'optimizer': 'rmsprop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvVSfu2PurMl",
    "outputId": "8c00a658-1eee-4214-a994-e3a06c68bcd9"
   },
   "outputs": [],
   "source": [
    "# history = models[0].fit(X_train, y_train, epochs=300, batch_size=8,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRKtYK-hCwas",
    "outputId": "bb95ff6f-8a01-4192-f71d-ae795ac25f99"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense,LeakyReLU, ELU, Activation\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, Nadam, RMSprop\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# import tensorflow as tf\n",
    "\n",
    "# best_model = Sequential()\n",
    "\n",
    "# best_model.add(Dense(units = 288, activation ='relu',input_dim=X_train.shape[1]))\n",
    "\n",
    "# best_model.add(Dense(units =464, activation = 'leaky_relu'))\n",
    "\n",
    "# best_model.add(Dense(units= 1, activation ='sigmoid'))\n",
    "\n",
    "# best_model.compile(optimizer = RMSprop(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# history = best_model.fit(X_train, y_train, epochs=100, batch_size=8,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91VfhK6k1_X2",
    "outputId": "db43f42b-8b75-4778-c902-2e1bbdaf107d"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# matrix_conf=confusion_matrix(y_test, best_model.predict(X_test).round())\n",
    "# accuracy_model=accuracy_score(y_test, best_model.predict(X_test).round())\n",
    "# print(f\"{matrix_conf=}\")\n",
    "# print(f'{accuracy_model=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "H45x03cyJ4Gp",
    "outputId": "97651f7d-8d23-4f44-bdf3-c4248a5032da"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def show_loss_acc(h):\n",
    "#   plt.figure(figsize=(12, 8))\n",
    "#   plt.subplot(2, 2, 1)\n",
    "#   plt.plot(h['loss'], label='train loss')\n",
    "#   plt.plot(h['val_loss'], label='val loss')\n",
    "#   plt.legend()\n",
    "#   plt.subplot(2, 2, 2)\n",
    "#   plt.plot(h['accuracy'], label='train accuracy')\n",
    "#   plt.plot(h['val_accuracy'], label='val accuracy')\n",
    "#   plt.legend()\n",
    "#   plt.show()\n",
    "# show_loss_acc(history.history)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
