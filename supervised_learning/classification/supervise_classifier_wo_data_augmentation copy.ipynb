{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing the data\n",
    "dataset = pd.read_excel('/Users/mustafa/Documents/GitHub/ML_knife_QA/data/chiefs_knife_dataset.xlsx')\n",
    "index_Ra = dataset.columns.get_loc('Ra')  # Index der Spalte für Rauheit\n",
    "\n",
    "# Spezifikationsgrenzen\n",
    "LOWER_SPECIFICATION_LIMIT = 0.125\n",
    "UPPER_SPECIFICATION_LIMIT = 0.215\n",
    "\n",
    "# Einteilung in \"gut\" und \"schlecht\"\n",
    "is_between_specification_bounds = (dataset['Ra'] >= LOWER_SPECIFICATION_LIMIT) & (dataset['Ra'] < UPPER_SPECIFICATION_LIMIT)\n",
    "good_product_range = np.where(is_between_specification_bounds, \"good\", \"bad\")\n",
    "dataset.insert(index_Ra + 1, 'Quality', good_product_range)\n",
    "\n",
    "# Features und Zielvariable\n",
    "X = dataset.loc[:, 'Original_Linienanzahl':'DFT_Median_sobel_Bereich'].values\n",
    "y = dataset['Quality'].values\n",
    "\n",
    "# Data Augmentation durch Rauschzugabe\n",
    "noise = np.random.normal(0, 0.01, X.shape)  # Rauschen mit Mittelwert 0 und Standardabweichung 0.01\n",
    "X_augmented = X + noise\n",
    "y_augmented = np.copy(y)  # Labels bleiben gleich\n",
    "\n",
    "# Verknüpfung von Original- und Augmented Features\n",
    "X_combined = np.vstack((X, X_augmented))\n",
    "y_combined = np.concatenate((y, y_augmented))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.70000000e+01  1.19310345e+01  2.00870480e+01 ...  2.60000000e+01\n",
      "   2.00000000e+00  2.40000000e+01]\n",
      " [ 7.70000000e+01  1.48831169e+01  2.29488273e+01 ...  2.60000000e+01\n",
      "   4.00000000e+00  2.20000000e+01]\n",
      " [ 5.90000000e+01  1.96779661e+01  3.18382781e+01 ...  1.60000000e+01\n",
      "   5.00000000e+00  1.10000000e+01]\n",
      " ...\n",
      " [ 9.93723333e-01  9.93468941e-01 -1.30763445e-02 ...  2.69993620e+01\n",
      "   1.99309488e+00  2.50092318e+01]\n",
      " [ 1.00663969e+00  1.01341673e+00 -2.14581095e-03 ...  2.49954164e+01\n",
      "   2.99579480e+00  2.20030958e+01]\n",
      " [ 9.94045386e-01  9.94401332e-01  1.31977327e-02 ...  2.79916869e+01\n",
      "   4.99609517e+00  2.29972671e+01]]\n",
      "['good' 'good' 'good' ... 'good' 'good' 'good']\n"
     ]
    }
   ],
   "source": [
    "print(X_combined)\n",
    "print(y_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Feature-Skalierung\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modelltraining mit RandomForestClassifier (Vor Randomized Search)\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluierung\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy (Original Model): {accuracy}')\n",
    "print(f'Classification Report (Original Model):\\n{report}')\n",
    "\n",
    "# Confusion Matrix für das Originalmodell\n",
    "cm_original = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_original, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Bad', 'Predicted Good'], yticklabels=['Actual Bad', 'Actual Good'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Original Model)')\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter-Raster für Randomized Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Randomized Search für Random Forest Classifier\n",
    "random_search_classifier = RandomizedSearchCV(estimator=classifier,\n",
    "                                              param_distributions=param_grid, \n",
    "                                              n_iter=100, # Anzahl der zufälligen Kombinationen\n",
    "                                              cv=5,       # Cross-Validation-Folds\n",
    "                                              scoring='accuracy', # search for the HP combination with the best accuracy\n",
    "                                              n_jobs=-1,  # Alle verfügbaren Kerne verwenden\n",
    "                                              verbose=2,  # Ausführlichkeit\n",
    "                                              random_state=42)  # Für Reproduzierbarkeit\n",
    "random_search_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Ausgabe der besten Hyperparameter\n",
    "print(f'Beste Hyperparameter für Classifier: {random_search_classifier.best_params_}')\n",
    "\n",
    "# Bestes Modell basierend auf der Suche\n",
    "best_model = random_search_classifier.best_estimator_\n",
    "\n",
    "# Vorhersagen mit dem besten Modell\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluierung des besten Modells\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "report_best = classification_report(y_test, y_pred_best)\n",
    "print(f'Best Model Accuracy: {accuracy_best}')\n",
    "print(f'Best Model Classification Report:\\n{report_best}')\n",
    "\n",
    "# Confusion Matrix für das beste Modell\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens', xticklabels=['Predicted Bad', 'Predicted Good'], yticklabels=['Actual Bad', 'Actual Good'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Best Model)')\n",
    "plt.show()\n",
    "\n",
    "# Feature Importances\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Namen der Features\n",
    "feature1 = dataset.columns.get_loc('Original_Linienanzahl')\n",
    "feature2 = dataset.columns.get_loc('DFT_Median_sobel_Bereich')\n",
    "feature_names = dataset.columns[feature1:feature2]\n",
    "\n",
    "# Visualisierung der Feature Importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "# Ausgabe der Feature Importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names[indices], 'Importance': importances[indices]})\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([True])\n",
    "b = np.array([False])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "v = np.concatenate([a,b])\n",
    "v.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
